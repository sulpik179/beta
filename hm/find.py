import csv



import re





# üîß –ù–∞—Å—Ç—Ä–æ–π–∫–∞ ‚Äî —É–∫–∞–∂–∏ –∏–º—è CSV-—Ñ–∞–π–ª–∞ (–ª—É—á—à–µ —É–∂–µ –æ—á–∏—â–µ–Ω–Ω—ã–π –∏ –±–µ–∑ –¥—É–±–ª–µ–π)


CSV_FILE = "csv/words.csv"  # ‚Üê –∏–∑–º–µ–Ω–∏, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ





# –ü—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞


words_data = []





try:


    with open(CSV_FILE, 'r', encoding='utf-8-sig') as f:


        reader = csv.reader(f, delimiter=';')


        words_data = list(reader)


    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(words_data)} —Å—Ç—Ä–æ–∫ –∏–∑ '{CSV_FILE}'\n")


except FileNotFoundError:


    print(f"‚ùå –§–∞–π–ª '{CSV_FILE}' –Ω–µ –Ω–∞–π–¥–µ–Ω. –ü—Ä–æ–≤–µ—Ä—å –∏–º—è –∏ –ø–∞–ø–∫—É.")


    exit(1)


except Exception as e:


    print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ: {e}")


    exit(1)





def normalize_ru(text: str) -> str:


    """–£–±–∏—Ä–∞–µ—Ç —ë/–µ –Ω–µ–æ–¥–Ω–æ–∑–Ω–∞—á–Ω–æ—Å—Ç—å –∏ –ø—Ä–∏–≤–æ–¥–∏—Ç –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É."""


    return text.lower().replace('—ë', '–µ')





print("üîç –í–≤–µ–¥–∏ —Å–ª–æ–≤–æ (–∞–Ω–≥–ª. –∏–ª–∏ —Ä—É—Å.) ‚Äî —è –Ω–∞–π–¥—É –µ–≥–æ –≤ –±–∞–∑–µ.")


print("   –ù–∞–ø–∏—à–∏ 'exit' –∏–ª–∏ 'quit', —á—Ç–æ–±—ã –≤—ã–π—Ç–∏.\n")





while True:


    query = input("üîé –ü–æ–∏—Å–∫: ").strip()


    if not query:


        continue


    if query.lower() in ('exit', 'quit'):


        print("üëã –î–æ –≤—Å—Ç—Ä–µ—á–∏!")


        break





    found = []


    query_lower = query.lower()


    query_ru_norm = normalize_ru(query)





    for idx, row in enumerate(words_data, start=1):


        if not row or len(row) < 2:


            continue





        eng = row[0].strip()


        ru = row[1].strip()





        # –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ (—Ä–µ–≥–∏—Å—Ç—Ä–æ–Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –¥–ª—è –∞–Ω–≥–ª., —Å —ë/–µ ‚Äî –¥–ª—è —Ä—É—Å.)


        if eng.lower() == query_lower or normalize_ru(ru) == query_ru_norm:


            found.append((idx, row))





    if found:


        print(f"\n‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(found)} —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π:\n")


        for idx, row in found:


            eng = row[0].strip()


            ru = row[1].strip()


            transcr = row[-1].strip() if len(row) > 2 else ""


            example_ru = row[6].strip() if len(row) > 6 else ""


            example_en = row[7].strip() if len(row) > 7 else ""





            print(f"üìå –°—Ç—Ä–æ–∫–∞ {idx}:")


            print(f"   üá¨üáß {eng}")


            print(f"   üá∑üá∫ {ru}")


            if transcr:


                print(f"   üîä /{transcr}/")


            if example_ru:


                print(f"   üìñ RU: {example_ru}")


            if example_en:


                print(f"   üìñ EN: {example_en}")


            print("-" * 50)


    else:


        print(f"\n‚ùå –°–ª–æ–≤–æ '{query}' –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ –±–∞–∑–µ.\n")


        # –ü–æ–¥—Å–∫–∞–∑–∫–∞: —á–∞—Å—Ç–∏—á–Ω—ã–π –ø–æ–∏—Å–∫ (–ø–µ—Ä–≤—ã–µ 3 —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –ø–æ –Ω–∞—á–∞–ª—É —Å–ª–æ–≤–∞)


        suggestions = []


        for idx, row in enumerate(words_data, start=1):


            if len(row) < 2: continue


            eng = row[0].strip()


            ru = row[1].strip()


            if eng.lower().startswith(query_lower) or normalize_ru(ru).startswith(query_ru_norm):


                suggestions.append((eng, ru))


                if len(suggestions) >= 3:


                    break


        if suggestions:


            print("üí° –í–æ–∑–º–æ–∂–Ω–æ, –≤—ã –∏–º–µ–ª–∏ –≤ –≤–∏–¥—É:")


            for eng, ru in suggestions:


                print(f"   ‚Ä¢ {eng} ‚Äî {ru}")


        print()